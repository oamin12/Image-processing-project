{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the figures / plots inside the notebook\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.misc\n",
    "from skimage.color import rgb2gray,rgb2hsv\n",
    "from Utility_Functions import *\n",
    "from skimage.exposure import histogram\n",
    "from poisson_blending import *\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./haar/haarcascade_frontalface_default.xml')\n",
    "mouth_cascade = cv2.CascadeClassifier('./haar/haarcascade_smile.xml')\n",
    "\n",
    "\n",
    "# if mouth_cascade.empty():\n",
    "#   raise IOError('Unable to load the mouth cascade classifier xml file')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hist(image, title, ignore_first=1, original_image=None):\n",
    "    \"\"\"\n",
    "    This is a helper function to plot a histogram of an image using matplotlib\n",
    "    \"\"\"\n",
    "    # Calculate the histogram\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    hist[0:ignore_first] = 0\n",
    "    if original_image is not None:\n",
    "        peaks_indices, hist = get_peaks(hist, original_image)\n",
    "    else:\n",
    "        peaks_indices, hist = get_peaks(hist, image)\n",
    "    print(peaks_indices)\n",
    "    # Ignore the first 'ignore_first' values in the histogram\n",
    "    \n",
    "\n",
    "    # Plot the modified histogram\n",
    "    plt.plot(hist, color='black')\n",
    "    plt.xlabel('Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def calcHist(img):\n",
    "\n",
    "    hist = np.zeros((256,1))\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            hist[img[i,j]] += 1\n",
    "    return hist\n",
    "    \n",
    "def showHist1(img):\n",
    "    # An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "    plt.figure()\n",
    "    imgHist = histogram(img, nbins=256)\n",
    "    \n",
    "    bar(imgHist[1].astype(np.uint8), imgHist[0], width=0.8, align='center')\n",
    "def show_image_3d(image):\n",
    "    \"\"\"\n",
    "    This is a helper function to plot a 3D plot of the image\n",
    "    \"\"\"\n",
    "    # Create the x and y coordinate arrays (here we just use pixel indices)\n",
    "    xx, yy = np.mgrid[0:image.shape[0], 0:image.shape[1]]\n",
    "\n",
    "    # Flatten xx and yy\n",
    "    x_flat = xx.ravel()\n",
    "    y_flat = yy.ravel()\n",
    "\n",
    "    # Get the values for each pixel\n",
    "    intensity = image.ravel()\n",
    "\n",
    "    # Setup a figure and axes\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot the values\n",
    "    ax.scatter(x_flat, y_flat, intensity, c=intensity, cmap='viridis')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def remove_background(image, rectangle, iterations=5):\n",
    "    \"\"\"\n",
    "    This is a helper function to use grabCut to remove the background from an image\n",
    "    \"\"\"\n",
    "    #This line creates an empty binary mask with the same dimensions as the input image \n",
    "    #The mask is initially filled with zeros, indicating that no pixels are currently classified as either foreground or background.\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    cv2.grabCut(image, mask, rectangle, None, None, iterations, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "    #if mask is 2 or 0, it is converted to 0, otherwise converted to 1\n",
    "    #2 or 0 means background, 1 or 3 means foreground\n",
    "    mask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "    #converting the input image to grayscale and applying the mask\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img = img * mask\n",
    "\n",
    "    return img\n",
    "\n",
    "def divide_image(image):\n",
    "    \"\"\"\n",
    "    This is a helper function to divide an image into 4 parts\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "\n",
    "    #this function takes an image and divide it into 4 parts\n",
    "    part1 = img[0:img.shape[0]//2, 0:img.shape[1]//2]\n",
    "    part2 = img[0:img.shape[0]//2, img.shape[1]//2:img.shape[1]]\n",
    "    part3 = img[img.shape[0]//2:img.shape[0], 0:img.shape[1]//2]\n",
    "    part4 = image[img.shape[0]//2:img.shape[0], img.shape[1]//2:img.shape[1]]\n",
    "\n",
    "    return part1, part2, part3, part4\n",
    "\n",
    "#this function takes an images and divide into 4 parts and calculate the histogram of each part\n",
    "def local_hist(image):\n",
    "    \"\"\"\n",
    "    This is a helper function that plots the histogram of each part of the image\n",
    "    \"\"\"\n",
    "    part1, part2, part3, part4 = divide_image(image)\n",
    "\n",
    "    show_hist(part1, 'Histogram of part1', original_image=image)\n",
    "    show_hist(part2, 'Histogram of part2', original_image=image)\n",
    "    show_hist(part3, 'Histogram of part3', original_image=image)\n",
    "    show_hist(part4, 'Histogram of part4', original_image=image)\n",
    "\n",
    "#this function takes array of threshold values and an image and return the image after applying the threshold to each part\n",
    "def local_thresholding(thresholds, image):\n",
    "    \"\"\"\n",
    "    This is a helper function that takes an array of threshold values \n",
    "    and an image and return the image after applying the threshold to each part\n",
    "    \"\"\"\n",
    "    # Create a copy of the image\n",
    "    image_thresholded = np.copy(image)\n",
    "\n",
    "    # Divide the image into 4 parts\n",
    "    part1 = image_thresholded[0:image.shape[0]//2, 0:image.shape[1]//2]\n",
    "    part2 = image_thresholded[0:image.shape[0]//2, image.shape[1]//2:image.shape[1]]\n",
    "    part3 = image_thresholded[image.shape[0]//2:image.shape[0], 0:image.shape[1]//2]\n",
    "    part4 = image_thresholded[image.shape[0]//2:image.shape[0], image.shape[1]//2:image.shape[1]]\n",
    "\n",
    "    # Apply thresholding\n",
    "    image_thresholded[0:image.shape[0]//2, 0:image.shape[1]//2] = np.where(part1 < thresholds[0], 0, 255)\n",
    "    image_thresholded[0:image.shape[0]//2, image.shape[1]//2:image.shape[1]] = np.where(part2 < thresholds[1], 0, 255)\n",
    "    image_thresholded[image.shape[0]//2:image.shape[0], 0:image.shape[1]//2] = np.where(part3 < thresholds[2], 0, 255)\n",
    "    image_thresholded[image.shape[0]//2:image.shape[0], image.shape[1]//2:image.shape[1]] = np.where(part4 < thresholds[3], 0, 255)\n",
    "    \n",
    "\n",
    "    return image_thresholded\n",
    "\n",
    "def get_peaks(hist, image):\n",
    "    \"\"\"\n",
    "    This is a helper function that takes and image and its histogram and return the peaks of the histogram\n",
    "    \"\"\"\n",
    "    \n",
    "    skin_color = image[0, 0]\n",
    "    #tooth color is the average color of 5x5 pixels in the middle of the image\n",
    "    tooth_color = image[(image.shape[0]//2)-40, image.shape[1]//2]\n",
    "    print(\"dist here \",tooth_color, skin_color)\n",
    "    dist = np.abs(np.abs(tooth_color.astype(np.float64)-skin_color.astype(np.float64))-10)\n",
    "    dist = dist if dist >= 1 else 125\n",
    "\n",
    "    #Here I am removing delta peaks\n",
    "    #which are peaks that are much higher than the neighboring point\n",
    "    hist_suppressed = suppress_delta_peaks(hist, percentage=0.45)\n",
    "\n",
    "    peaks_indices, _ = find_peaks(hist_suppressed.flatten(), distance=dist, height=0.4*max(hist.flatten()))\n",
    "    return peaks_indices, hist_suppressed\n",
    "\n",
    "\n",
    "def get_peaks_local(image):\n",
    "    \"\"\"\n",
    "    This is a helper function that takes an image and returns the peaks of the histogram of each part of the image\n",
    "    \"\"\"\n",
    "    part1, part2, part3, part4 = divide_image(image)\n",
    "\n",
    "    hist1 = cv2.calcHist([part1], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([part2], [0], None, [256], [0, 256])\n",
    "    hist3 = cv2.calcHist([part3], [0], None, [256], [0, 256])\n",
    "    hist4 = cv2.calcHist([part4], [0], None, [256], [0, 256])\n",
    "\n",
    "    peak1, _ = get_peaks(hist1, image)\n",
    "    peak2, _ = get_peaks(hist2, image)\n",
    "    peak3, _ = get_peaks(hist3, image)\n",
    "    peak4, _ = get_peaks(hist4, image)\n",
    "\n",
    "    return peak1, peak2, peak3, peak4\n",
    "\n",
    "def get_threshold_between_2_peaks(peak1, peak2, img):\n",
    "    \"\"\"\n",
    "    This is a helper function that takes an image and 2 peaks and returns the threshold between them using Iterative Threshold Selection \n",
    "    \"\"\"\n",
    "    \n",
    "    min_value = 255\n",
    "    min_index = 0\n",
    "    hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "    \n",
    "    for i in range(0, peak2-peak1):\n",
    "        if hist[i] < min_value:\n",
    "            min_value = hist[i]\n",
    "            min_index = i\n",
    "\n",
    "    return min_index + peak1 + 40\n",
    "\n",
    "def get_max_gap(hist):\n",
    "    \"\"\"\n",
    "    This is a helper function that takes a histogram and returns the index and value of the maximum gap\n",
    "    \"\"\"\n",
    "    max_gap = 0\n",
    "    max_gap_index = 0\n",
    "    for i in range(1, len(hist)-1):\n",
    "        if hist[i] > hist[i-1] and hist[i] > hist[i+1]:\n",
    "            if hist[i]-hist[i-1] > max_gap and hist[i]-hist[i+1] > max_gap:\n",
    "                max_gap = hist[i]-hist[i-1]\n",
    "                max_gap_index = i\n",
    "\n",
    "    #for the first point\n",
    "    if hist[0] > hist[1] and hist[0]-hist[1] > max_gap:\n",
    "        max_gap = hist[0]-hist[1]\n",
    "        max_gap_index = 0\n",
    "\n",
    "    #for the last point\n",
    "    if hist[-1] > hist[-2] and hist[-1]-hist[-2] > max_gap:\n",
    "        max_gap = hist[-1]-hist[-2]\n",
    "        max_gap_index = len(hist)-1\n",
    "\n",
    "    return max_gap, max_gap_index\n",
    "\n",
    "def suppress_delta_peaks(hist, percentage=0.5):\n",
    "    \"\"\"\n",
    "    This is a helper function that takes a histogram and percentage and returns the histogran after suppressing the delta peaks\n",
    "    \"\"\"\n",
    "    #Here I am removing delta peaks\n",
    "    #the method is to remove peaks that are much higher than the neighboring peaks\n",
    "    #I am calculating the difference between each peak and its left and right neighbors\n",
    "    #if the difference is higher than a threshold, then I am removing this peak\n",
    "    my_hist = hist.copy()   \n",
    "    hist_max_gap = get_max_gap(hist)[0]\n",
    "    threshold = int(hist_max_gap*percentage)\n",
    "\n",
    "    for i in range(1, len(hist)-1):\n",
    "        if hist[i] > hist[i-1] and hist[i] > hist[i+1]:\n",
    "            if hist[i]-hist[i-1] > threshold and hist[i]-hist[i+1] > threshold:\n",
    "                my_hist[i] = (hist[i-1] + hist[i+1])//2\n",
    "\n",
    "    return my_hist\n",
    "\n",
    "def getThreshold(img):\n",
    "    # img = image.copy()\n",
    "    # if (len(img.shape) == 3):\n",
    "    #     img = rgb2gray(img)\n",
    "    #     img = (img * 255).astype(np.uint8)\n",
    "    hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "    imgHist = hist#calcHist(img)\n",
    "    T_init = 0\n",
    "    T = 0\n",
    "    # Get the initial threshold Tinit (the mean of the image)\n",
    "    for k in range(256):\n",
    "        T_init += k*imgHist[k]\n",
    "    T_init = np.round(T_init / np.sum(imgHist))\n",
    "    \n",
    "    # Get the two weighted averages (means), one for the lower pixels (have gray level less than Tinit) and the other for the higher pixels (have gray level more than Tinit)\n",
    "    while True:\n",
    "        sum1 = 0\n",
    "        sum2 = 0\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        for k in range(256):\n",
    "            if k < T_init:\n",
    "                sum1 += k*imgHist[k]\n",
    "                count1 += imgHist[k]\n",
    "            else:\n",
    "                sum2 += k*imgHist[k]\n",
    "                count2 += imgHist[k]\n",
    "                \n",
    "        m1 = sum1/ count1\n",
    "        m2 = sum2/ count2\n",
    "        \n",
    "        T = np.round((m1 + m2) / 2)\n",
    "        if T == T_init:\n",
    "            break\n",
    "        else:\n",
    "            T_init = T\n",
    "    return int(T)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the image and applying face detection using haar cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input image\n",
    "image_path = './images/img1.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "#resize image 716x900\n",
    "img = cv2.resize(img, (716, 900))\n",
    "\n",
    "def face_detection(img):\n",
    "\n",
    "    # Perform face detection\n",
    "    faces = face_cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    return img, faces\n",
    "\n",
    "def draw_rectangles(img, faces):\n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    return img, faces\n",
    "\n",
    "# # Display the result\n",
    "# cv2.imshow('Face Detection', img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove background using Grabcut algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_temp = img.copy()\n",
    "# img_temp = remove_background(img, faces[0], iterations=5)\n",
    "\n",
    "# cv2.imshow(\"Foreground\", img_temp)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmenting the mouth area from the face and applying gamma correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segment the face\n",
    "def segment_face(img_temp, faces):\n",
    "    img_temp = cv2.cvtColor(img_temp, cv2.COLOR_BGR2GRAY)\n",
    "    for (x, y, w, h) in faces:\n",
    "        #take the region of interest which is the face\n",
    "        roi_gray = img_temp[y:y+h, x:x+w]\n",
    "        \n",
    "        #then take the mouth region only\n",
    "        roi_gray_mouth_region = roi_gray[int(roi_gray.shape[0]/1.5):roi_gray.shape[0], int(roi_gray.shape[1]/4):int(roi_gray.shape[1]/4)+int(roi_gray.shape[1]/2)]\n",
    "\n",
    "        # cv2.imshow('mouth Segmentation before gamma correction', roi_gray_mouth_region)\n",
    "\n",
    "        #plot histogram\n",
    "        show_hist(roi_gray_mouth_region, \"before gamma correction\")\n",
    "        \n",
    "        #apply gamma correction\n",
    "        gamma = 1\n",
    "        roi_gray_mouth_region = np.array(255 * (roi_gray_mouth_region / 255) ** gamma, dtype = 'uint8')\n",
    "\n",
    "        #plot histogram\n",
    "        show_hist(roi_gray_mouth_region, \"after gamma correction\")\n",
    "    return roi_gray_mouth_region, roi_gray\n",
    "\n",
    "# cv2.imshow('mouth Segmentation after gamma correction', roi_gray_mouth_region)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_hist(roi_gray_mouth_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying segmentation using threshholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the image into 4 parts and calculate the histogram of each part\n",
    "def teeth_segmentation(roi_gray_mouth_region):\n",
    "    part1, part2, part3, part4 = divide_image(roi_gray_mouth_region)\n",
    "    peak1, peak2, peak3, peak4 = get_peaks_local(roi_gray_mouth_region)\n",
    "\n",
    "    #puting the peaks in an array to make it easy to loop over them\n",
    "    hist_peaks = [peak1, peak2, peak3, peak4]\n",
    "    img_parts = [part1, part2, part3, part4]\n",
    "\n",
    "    for i in range(len(hist_peaks)):\n",
    "        #if there is one peak only, then put hist_peaks[i] = 255\n",
    "        if len(hist_peaks[i]) == 1:\n",
    "            hist_peaks[i] = 255\n",
    "        else:\n",
    "            hist_peaks[i] = get_threshold_between_2_peaks(hist_peaks[i][-2], hist_peaks[i][-1], img_parts[i][0])\n",
    "            #hist_peaks[i] = getThreshold(img_parts[i][0]) \n",
    "            \n",
    "    print(hist_peaks)\n",
    "    roi_gray_mouth_region = local_thresholding(hist_peaks, roi_gray_mouth_region)\n",
    "    return roi_gray_mouth_region\n",
    "\n",
    "\n",
    "# cv2.imshow('After Threshholding', roi_gray_mouth_region)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color Segmentation\n",
    "#notes\n",
    "#isolate the skin color using hsv\n",
    "#select teeth color using hsv\n",
    "\n",
    "def color_segmentation(original_img_copy, roi_gray_mouth_region, faces):\n",
    "    img_copy1 = cv2.cvtColor(original_img_copy, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Take the region of interest which is the face\n",
    "        face_region = img_copy1[y:y+h, x:x+w]\n",
    "        \n",
    "        # Then take the mouth region only\n",
    "        mouth_region = face_region[int(face_region.shape[0]/1.5):face_region.shape[0],\n",
    "                                    int(face_region.shape[1]/4):int(face_region.shape[1]/4)+int(face_region.shape[1]/2)]\n",
    "        \n",
    "    #convert to hsv color space to inhance the saturation\n",
    "    mouth_region = cv2.cvtColor(mouth_region, cv2.COLOR_RGB2HSV)\n",
    "    mouth_region[:,:,1] = mouth_region[:,:,1] * 1.3\n",
    "    #decrease the value to make the image darker\n",
    "    mouth_region[:,:,2] = mouth_region[:,:,2] * 0.7\n",
    "\n",
    "    mouth_region = cv2.cvtColor(mouth_region, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    show_images([mouth_region], ['Mouth Segmentation higher saturation'])\n",
    "\n",
    "    Z = mouth_region.reshape((-1,3))\n",
    "    # convert to np.float32\n",
    "    Z = np.float32(Z)\n",
    "    # define criteria, number of clusters(K) and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 4\n",
    "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    # Now convert back into uint8, and make original image\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((mouth_region.shape))\n",
    "\n",
    "    show_images([res2], ['mouth segmentation Kmeans Output'])\n",
    "\n",
    "\n",
    "    #plot histogram\n",
    "    gray_img2 = cv2.cvtColor(res2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    show_images([gray_img2], ['mouth segmentation Kmeans Output gray'])\n",
    "\n",
    "    #apply gaussian filter\n",
    "    gray_img2 = cv2.GaussianBlur(gray_img2, (5, 5), 5)\n",
    "\n",
    "\n",
    "    #apply median filter\n",
    "    #gray_img2 = cv2.medianBlur(gray_img2, 5)\n",
    "\n",
    "    show_images([gray_img2], ['mouth segmentation'])\n",
    "    imgHist = calcHist(gray_img2)\n",
    "\n",
    "    print(imgHist.shape)\n",
    "\n",
    "    brightest = 0\n",
    "    for i in range(0, len(imgHist)):\n",
    "        if imgHist[i][0] > 0:\n",
    "            if i > brightest:\n",
    "                brightest = i\n",
    "\n",
    "    threshold = brightest\n",
    "    print(\"threshold\", threshold)\n",
    "\n",
    "    new_thresholded_img = gray_img2.copy()\n",
    "\n",
    "    new_thresholded_img = gray_img2 >= threshold\n",
    "\n",
    "\n",
    "    #opening to remove noise\n",
    "\n",
    "    # Define the dimensions of the ellipse (width and height)\n",
    "    ellipse_width = 10\n",
    "    ellipse_height = 5\n",
    "\n",
    "    # Create an elliptical kernel\n",
    "    ellipse_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ellipse_width, ellipse_height))\n",
    "\n",
    "    new_thresholded_img = cv2.morphologyEx(new_thresholded_img.astype(np.uint8), cv2.MORPH_OPEN, ellipse_kernel)\n",
    "\n",
    "    ellipse_width = 20\n",
    "    ellipse_height = 10\n",
    "\n",
    "    # Create an elliptical kernel\n",
    "    ellipse_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ellipse_width, ellipse_height))\n",
    "\n",
    "\n",
    "    #closing to fill holes\n",
    "    new_thresholded_img = cv2.morphologyEx(new_thresholded_img.astype(np.uint8), cv2.MORPH_CLOSE, ellipse_kernel)\n",
    "\n",
    "    #apply dilation to make the teeth thicker\n",
    "\n",
    "    ellipse_width = 20\n",
    "    ellipse_height = 10\n",
    "\n",
    "    # Create an elliptical kernel\n",
    "    ellipse_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ellipse_width, ellipse_height))\n",
    "\n",
    "    new_thresholded_img = cv2.dilate(new_thresholded_img.astype(np.uint8), ellipse_kernel, iterations=6)\n",
    "\n",
    "\n",
    "\n",
    "    #remove outliers from the image\n",
    "\n",
    "\n",
    "    show_images([new_thresholded_img], ['teeth segmentation'])\n",
    "\n",
    "    return new_thresholded_img, roi_gray_mouth_region, mouth_region\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying opening to remove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_opening(roi_gray_mouth_region):\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "\n",
    "    # Define the dimensions of the ellipse (width and height)\n",
    "    ellipse_width = 10\n",
    "    ellipse_height = 5\n",
    "\n",
    "    # Create an elliptical kernel\n",
    "    ellipse_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ellipse_width, ellipse_height))\n",
    "\n",
    "    # Apply opening operation to the binary mask\n",
    "    opened_mask = cv2.morphologyEx(roi_gray_mouth_region, cv2.MORPH_OPEN, ellipse_kernel, iterations=2)\n",
    "\n",
    "    roi_gray_mouth_region = roi_gray_mouth_region * opened_mask\n",
    "    return roi_gray_mouth_region, opened_mask\n",
    "\n",
    "# cv2.imshow(\"Opened Mask\", roi_gray_mouth_region*255)  # Multiply by 255 for better visualization\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying dilation to take the whole mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dilation(roi_gray_mouth_region):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # Define the dimensions of the ellipse (width and height)\n",
    "    ellipse_width = 10\n",
    "    ellipse_height = 5\n",
    "\n",
    "    # Create an elliptical kernel\n",
    "    ellipse_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ellipse_width, ellipse_height))\n",
    "\n",
    "\n",
    "    # Apply closing operation to the binary mask\n",
    "    dilate_mask = cv2.morphologyEx(roi_gray_mouth_region, cv2.MORPH_DILATE, ellipse_kernel, iterations=6)\n",
    "\n",
    "    roi_gray_mouth_region = cv2.bitwise_or(roi_gray_mouth_region, dilate_mask)\n",
    "    return roi_gray_mouth_region, dilate_mask\n",
    "\n",
    "# cv2.imshow(\"Opened Mask\", roi_gray_mouth_region*255)  # Multiply by 255 for better visualization\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply closing to close gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_closing(roi_gray_mouth_region):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # # Define the dimensions of the ellipse (width and height)\n",
    "    # ellipse_width = 5\n",
    "    # ellipse_height = 10\n",
    "\n",
    "    # # Create an elliptical kernel\n",
    "    # ellipse_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ellipse_width, ellipse_height))\n",
    "\n",
    "\n",
    "    # Apply closing operation to the binary mask\n",
    "    close_mask = cv2.morphologyEx(roi_gray_mouth_region, cv2.MORPH_CLOSE, kernel, iterations=5)\n",
    "    roi_gray_mouth_region = cv2.bitwise_or(roi_gray_mouth_region, close_mask)\n",
    "    return roi_gray_mouth_region, close_mask\n",
    "\n",
    "# cv2.imshow(\"closemask\", roi_gray_mouth_region*255)  # Multiply by 255 for better visualization\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting in 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_image_3d(roi_gray_mouth_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mean position of 1's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mouth_translation(roi_gray_mouth_region):\n",
    "    # Find the coordinates of all ones\n",
    "    rows, cols = np.where(roi_gray_mouth_region == 1)\n",
    "\n",
    "    img_center_y = roi_gray_mouth_region.shape[0]//2\n",
    "    img_center_x = roi_gray_mouth_region.shape[1]//2\n",
    "\n",
    "    # Calculate the mean position\n",
    "    mean_row = np.mean(rows)\n",
    "    mean_col = np.mean(cols)\n",
    "\n",
    "    print(mean_row, mean_col)\n",
    "\n",
    "    #I want to shift the image so that the mean position is in the center of the image\n",
    "    shift_x = img_center_x - mean_col\n",
    "    shift_y = img_center_y - mean_row\n",
    "\n",
    "    # Define the translation matrix\n",
    "    translation_matrix = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "\n",
    "    # Translate the mask for anaylsis purposes\n",
    "    img_translation = cv2.warpAffine(roi_gray_mouth_region, translation_matrix, (roi_gray_mouth_region.shape[1], roi_gray_mouth_region.shape[0]))\n",
    "\n",
    "    show_image_3d(img_translation)\n",
    "\n",
    "    return img_translation, translation_matrix\n",
    "\"\"\"\n",
    "NOTE: the tansalation will not happen on the mask, it has to applied after the mask is applied to the image\n",
    "Here I am just showing the translation on the mask to make it easy to understand and analyze\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the mouth from the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have the mouth region only\n",
    "#We want to extract the lips from the orignal image\n",
    "def extract_mouth(img, faces, roi_gray, roi_gray_mouth_region):\n",
    "    for (x, y, w, h) in faces:\n",
    "        \n",
    "        mouth_region = img[y+int(roi_gray.shape[0]/1.5):y+h, x+int(roi_gray.shape[1]/4):x+int(roi_gray.shape[1]/4)+int(roi_gray.shape[1]/2)] \n",
    "\n",
    "        if mouth_region.shape[0] != roi_gray_mouth_region.shape[0] or mouth_region.shape[1] != roi_gray_mouth_region.shape[1]:\n",
    "            print(\"Error: the mouth region and the mask are not the same size\")\n",
    "            continue\n",
    "        #apply the mask to the mouth region\n",
    "        #here we convert the mask to 3d to apply it to the mouth region\n",
    "        #np.stack((roi_gray_mouth_region,) * 3, axis=-1) converts the mask to 3d in the last axis which is the color axis\n",
    "        roi_gray_mouth_region_3d = np.stack((roi_gray_mouth_region,) * 3, axis=-1)\n",
    "        mouth_region = mouth_region * roi_gray_mouth_region_3d\n",
    "    return mouth_region\n",
    "   \n",
    "# cv2.imshow('mouth Segmentation', mouth_region)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_image(mouth_region, roi_gray_mouth_region, translation_matrix):\n",
    "    mouth_region = cv2.warpAffine(mouth_region, translation_matrix, (roi_gray_mouth_region.shape[1], roi_gray_mouth_region.shape[0]))\n",
    "    roi_gray_mouth_region = cv2.warpAffine(roi_gray_mouth_region, translation_matrix, (roi_gray_mouth_region.shape[1], roi_gray_mouth_region.shape[0]))\n",
    "\n",
    "    # cv2.imshow('mouth Segmentation', roi_gray_mouth_region*255)\n",
    "\n",
    "    #get left most point in the mask and the right most point and the top most point and the bottom most point\n",
    "    #these points will be used to crop the image\n",
    "\n",
    "    print(roi_gray_mouth_region.shape)\n",
    "    left_most_point = (roi_gray_mouth_region.shape[0], roi_gray_mouth_region.shape[1])\n",
    "    right_most_point = (0, 0)\n",
    "    top_most_point = (roi_gray_mouth_region.shape[0], roi_gray_mouth_region.shape[1])\n",
    "    bottom_most_point = (0, 0)\n",
    "\n",
    "\n",
    "\n",
    "    print(left_most_point)\n",
    "\n",
    "    for i in range(roi_gray_mouth_region.shape[0]):\n",
    "        for j in range(roi_gray_mouth_region.shape[1]):\n",
    "            if roi_gray_mouth_region[i][j] == 1:\n",
    "                if i < left_most_point[0]:\n",
    "                    left_most_point = (i, j)\n",
    "                if i > right_most_point[0]:\n",
    "                    right_most_point = (i, j)\n",
    "                if j < top_most_point[1]:\n",
    "                    top_most_point = (i, j)\n",
    "                if j > bottom_most_point[1]:\n",
    "                    bottom_most_point = (i, j)\n",
    "\n",
    "\n",
    "\n",
    "    print (left_most_point, right_most_point, top_most_point, bottom_most_point)\n",
    "\n",
    "    #crop the image using the points we got\n",
    "    mouth_region = mouth_region[left_most_point[0]:right_most_point[0], top_most_point[1]:bottom_most_point[1]]\n",
    "    roi_gray_mouth_region = roi_gray_mouth_region[left_most_point[0]:right_most_point[0], top_most_point[1]:bottom_most_point[1]]\n",
    "\n",
    "    return mouth_region, roi_gray_mouth_region\n",
    "\n",
    "\n",
    "\n",
    "# cv2.imshow('transalation', mouth_region)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('transalation', mouth_region)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the second image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2_path = './images/amin2.png'\n",
    "img2 = cv2.imread(image2_path)\n",
    "\n",
    "#resize image 716x900\n",
    "img2 = cv2.resize(img2, (716, 1000))\n",
    "\n",
    "##  ##\n",
    "# Perform face detection\n",
    "faces2 = face_cascade.detectMultiScale(img2, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "\n",
    "\n",
    "# cv2.imshow('Face Detection 2', img2)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the mask to the second image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_image(img2, faces2, mouth_region, roi_gray_mouth_region):\n",
    "    for (x2, y2, w2, h2) in faces2:\n",
    "\n",
    "        #take the region of interest which is the face\n",
    "        roi2 = img2[y2:y2+h2, x2:x2+w2]\n",
    "        \n",
    "        #and here I am taking the mouth region only, which will help me to detect the mouth region in the second image using haar\n",
    "        #haar cascade works better with small images, it doesn't work well with large images\n",
    "        #so I am taking the mouth region only to detect the mouth region in the second image\n",
    "        mouth2_region = roi2[int(roi2.shape[0]/1.5):roi2.shape[0], int(roi2.shape[1]/4):int(roi2.shape[1]/4)+int(roi2.shape[1]/2)]\n",
    "\n",
    "        #using haar cascade to detect the mouth region\n",
    "        mouth2 = mouth_cascade.detectMultiScale(mouth2_region, scaleFactor=1.1, minNeighbors=5, minSize=(100, 100))\n",
    "\n",
    "        # for (mx2, my2, mw2, mh2) in mouth2:\n",
    "        #     cv2.rectangle(mouth2_region, (mx2, my2), (mx2+mw2, my2+mh2), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        [mx2, my2, mw2, mh2] = mouth2[0]\n",
    "        mouth2_region = mouth2_region[my2:my2+mh2, mx2:mx2+mw2]\n",
    "\n",
    "\n",
    "        #resize the mouth region to the same size of the mouth region of the second image\n",
    "        mouth_region_resized = cv2.resize(mouth_region, (mw2, mh2))\n",
    "        roi_gray_mouth_region_resized = cv2.resize(roi_gray_mouth_region, (mw2, mh2))\n",
    "\n",
    "\n",
    "        im_mask = np.full(mouth2_region.shape, 255, dtype = np.uint8)\n",
    "    \n",
    "        center = (int(mouth_region_resized.shape[1]/2), int(mouth_region_resized.shape[0]/2))\n",
    "\n",
    "        im_clone = cv2.seamlessClone(mouth2_region, mouth_region_resized, im_mask, center, cv2.MIXED_CLONE)\n",
    "\n",
    "        # cv2.imshow(\"clone\", im_clone)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        #USING THE SEAMLESS CLONE FUNCTION TO BLEND THE TWO IMAGES\n",
    "        # put the mouth region in the second image\n",
    "        # for i in range(mouth2_region.shape[0]):\n",
    "        #     for j in range(mouth2_region.shape[1]):\n",
    "        #         if roi_gray_mouth_region_resized[i][j] == 1:\n",
    "        #             #blend colors\n",
    "        #             mouth2_region[i][j] = im_clone[i][j]\n",
    "        \n",
    "        # put the mouth region in the second image\n",
    "        for i in range(mouth2_region.shape[0]):\n",
    "            for j in range(mouth2_region.shape[1]):\n",
    "                if roi_gray_mouth_region_resized[i][j] == 1:\n",
    "                    #blend colors\n",
    "                    mouth2_region[i][j] = mouth_region_resized[i][j]\n",
    "        \n",
    "    \n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "    mouth2_region = cv2.cvtColor(mouth2_region, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # cv2.imshow('mouth2_region', mouth2_region)\n",
    "    # cv2.imshow('Result', img2)\n",
    "    show_images([mouth2_region, img2], ['mouth2_region', 'Result'])\n",
    "\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return img2, mouth2_region\n",
    "\n",
    "\n",
    "\n",
    "# cv2.imshow('mouth2_region', mouth2_region)\n",
    "# cv2.imshow('Result', img2)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUI\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter.filedialog import askopenfile\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "my_w = tk.Tk()\n",
    "my_w.geometry(\"1500x800\")  # Size of the window \n",
    "my_w.title('Image Processing Project')\n",
    "my_font1 = ('times', 18, 'bold')\n",
    "\n",
    "# Initialize separate global variables for each image\n",
    "img1 = None\n",
    "img2 = None\n",
    "img3 = None\n",
    "\n",
    "# Label and Button styling\n",
    "label_style = {'width': 30, 'font': my_font1}\n",
    "button_style = {'width': 20, 'bg': '#063462', 'fg': 'white', 'font': my_font1, 'borderwidth': 2, 'relief': 'groove', 'overrelief': 'ridge'}\n",
    "\n",
    "l1 = tk.Label(my_w, text='Add the first Photo', **label_style)  \n",
    "l1.grid(row=1, column=1)\n",
    "b1 = tk.Button(my_w, text='Upload Image', command=lambda: upload_file1(), **button_style)\n",
    "b1.grid(row=2, column=1, pady=10)\n",
    "\n",
    "l2 = tk.Label(my_w, text='Add the second Photo', **label_style)  \n",
    "l2.grid(row=1, column=2)\n",
    "b2 = tk.Button(my_w, text='Upload Image', command=lambda: upload_file2(), **button_style)\n",
    "b2.grid(row=2, column=2, pady=10)\n",
    "\n",
    "b3 = tk.Button(my_w, text='Generate Output Image', command=lambda: generate_output(), **button_style)\n",
    "b3.grid(row=2, column=3, pady=10)\n",
    "\n",
    "def upload_file1():\n",
    "    global img1, filename1\n",
    "    f_types = [('Image Files', '*.png;*.gif;*.ppm;*.pgm;*.pbm;*.tiff;*.bmp;*.jpeg;*.jpg')]\n",
    "    filename1 = filedialog.askopenfilename(filetypes=f_types)\n",
    "    if filename1:\n",
    "        img1 = Image.open(filename1)\n",
    "        img_resized = img1.resize((400, 600))  # new width & height\n",
    "        img1 = ImageTk.PhotoImage(img_resized)\n",
    "        b2 = tk.Button(my_w, image=img1)  # using Button\n",
    "        b2.grid(row=3, column=1)\n",
    "\n",
    "def upload_file2():\n",
    "    global img2, filename2\n",
    "    f_types = [('Image Files', '*.png;*.gif;*.ppm;*.pgm;*.pbm;*.tiff;*.bmp;*.jpeg;*.jpg')]\n",
    "    filename2 = filedialog.askopenfilename(filetypes=f_types)\n",
    "    if filename2:\n",
    "        img2 = Image.open(filename2)\n",
    "        img_resized = img2.resize((400, 600))  # new width & height\n",
    "        img2 = ImageTk.PhotoImage(img_resized)\n",
    "        b2 = tk.Button(my_w, image=img2)  # using Button\n",
    "        b2.grid(row=3, column=2)\n",
    "\n",
    "def generate_output():\n",
    "    # if this button is clicked, then the output image will be generated\n",
    "    global img1, img2, img3\n",
    "    if img1 and img2:\n",
    "        img1_copy = cv2.imread(filename1)\n",
    "        img2_copy = cv2.imread(filename2)\n",
    "\n",
    "        img1_copy = cv2.resize(img1_copy, (716, 900))\n",
    "        img2_copy = cv2.resize(img2_copy, (716, 1000))\n",
    "\n",
    "        img1_copy, faces1 = face_detection(img1_copy)\n",
    "        img1_copy, faces1 = draw_rectangles(img1_copy, faces1)\n",
    "        roi_gray_mouth_region1, roi_gray1 = segment_face(img1_copy, faces1)\n",
    "\n",
    "        local_hist(roi_gray_mouth_region1)\n",
    "        \n",
    "        roi_gray_mouth_region1 = teeth_segmentation(roi_gray_mouth_region1)\n",
    "        \n",
    "        new_thresholded_img, roi_gray_mouth_region1, mouth_region1 = color_segmentation(img1_copy, roi_gray_mouth_region1, faces1)\n",
    "\n",
    "        roi_gray_mouth_region1, opened_mask1 = apply_opening(roi_gray_mouth_region1)\n",
    "        roi_gray_mouth_region1, dilate_mask1 = apply_dilation(roi_gray_mouth_region1)\n",
    "        roi_gray_mouth_region1, close_mask1 = apply_closing(roi_gray_mouth_region1)\n",
    "\n",
    "        roi_gray_mouth_region1 = new_thresholded_img\n",
    "\n",
    "        roi_gray_mouth_region1, translation_matrix1 = apply_mouth_translation(roi_gray_mouth_region1)\n",
    "\n",
    "        mouth_region1 = extract_mouth(img1_copy, faces1, roi_gray1, roi_gray_mouth_region1)\n",
    "\n",
    "        mouth_region1, roi_gray_mouth_region1 = translate_image(mouth_region1, roi_gray_mouth_region1, translation_matrix1)\n",
    "\n",
    "        img2_copy, faces2 = face_detection(img2_copy)\n",
    "\n",
    "        img3, mouth2_region = generate_output_image(img2_copy, faces2, mouth_region1, roi_gray_mouth_region1)\n",
    "\n",
    "        img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
    "        # cv2.imshow('Result', img3)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        # Convert the OpenCV image to a PIL Image\n",
    "        img3_pil = Image.fromarray(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))\n",
    "        img3_pil = img3_pil.resize((400, 600))  # new width & height\n",
    "\n",
    "        # Convert the PIL Image to PhotoImage\n",
    "        img3 = ImageTk.PhotoImage(img3_pil)\n",
    "\n",
    "        # Use Label widget to display the image\n",
    "        label_img3 = tk.Label(my_w, image=img3)\n",
    "        label_img3.grid(row=3, column=3)\n",
    "\n",
    "        # img3 = ImageTk.PhotoImage(img3)\n",
    "        # b3 = tk.Button(my_w, image=img3)  # using Button\n",
    "        # b3.grid(row=3, column=3)\n",
    "\n",
    "my_w.mainloop()  # Keep the window open"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
